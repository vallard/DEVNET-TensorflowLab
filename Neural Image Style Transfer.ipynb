{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Image Style Transfer Lab\n",
    "One of the really cool applications of deep learning that has come lately is the idea of neural image style transfers.  Take a look at [https://deepart.io](https://deepart.io) to get an idea of what it can do. Based off [the paper on Neural image style transfer](https://arxiv.org/pdf/1508.06576.pdf), we can take an image (source) and a style image (like a famous painting) and generate an image based on the style.  To begin, let's import all the required libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "from nist import *\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000 # make it so we can accept bigger images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to select which images we will use.  This is the part where you can change the images to process.  We can do that later.  For now, lets use the images that are in the lab.  First we have a ```content_image_name```.  This is the image that we want modified in a cool new style.  We also have the ```style_image_name```.  This is the Van Gogh image of _Starry Night_.  We will use the style from this painting and apply it to the ```content_image```.  To add your own images for use, simply upload them into the [images directory](./images).  Don't worry, these images will go away when the sandbox terminates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image_name = \"images/Devnet_Sandbox_CLus2_300DPI.png\"  # This is the image we want to enhance with a style\n",
    "style_image_name = \"images/starry_night@2000x1500.jpg\" # This is the style image.  We will take this image to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table><tr><td><img src=\"images/Devnet_Sandbox_CLus2_300DPI.png\" width=400 alt=\"DEVI picture\"/></td>\n",
    "    <td><img src=\"images/starry_night@2000x1500.jpg\" width=400 alt=\"Starry Night\" /></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our program expects the images to be 2000px width x 1500px height so we will need to reformat the images to make it 2000x1500.  Then we need to take the image and turn it into an matrix.  The matrix will then be a 2000x1500x3 matrix.  The 3 comes from the RGB spectrum of colors. Let's create a function that does that.  \n",
    "\n",
    "It turns out that a lot of time spent on data science involves data wrangling and manipulating data to get it into the right form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_to_size(image):\n",
    "    \"\"\"\n",
    "    Takes in an image, converts the image to a 2000x1500 size then turns it into an array\n",
    "    of dimension IMAGE_WIDTHxIMAGE_HEIGHTx3\n",
    "    \"\"\"\n",
    "    img = Image.open(image).convert(\"RGB\") #open with RGB\n",
    "    img = img.resize((CONFIG.IMAGE_WIDTH,CONFIG.IMAGE_HEIGHT), Image.ANTIALIAS) # Resize to IMAGE_WIDTHxIMAGE_HEIGHT\n",
    "    img = reshape_and_normalize_image(np.asarray(img)) # Normalize with mean values\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run our images through the function and check the array sizes that we get from it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 900, 1200, 3)\n",
      "(1, 900, 1200, 3)\n"
     ]
    }
   ],
   "source": [
    "content_image = format_to_size(content_image_name)\n",
    "style_image = format_to_size(style_image_name)\n",
    "print(content_image.shape)\n",
    "print(style_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now run these two images through the neural network.  The neural network itself, while interesting, is beyond the scope of this lab to understand.  What is important to understand is that many of the algorithms that have been created for deep neural networks are open source and available to use, even if you don't understand too many of the details behind them.  In this case a model has already been created and trained.  The [paper](https://arxiv.org/pdf/1508.06576.pdf) uses the imagenet-vgg-verydeep-19.mat model.  We use the exact same one and run our algorithm through it. Even with the GPU it takes about 5 minutes for this next part to run.  So sit back as it runs through the neural network 100 times and each time enhances the style. You can run this code on your laptop as well and it takes about 45 minutes to run through the whole thing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 :\n",
      "total cost = 3553763000.0\n",
      "content cost = 17302.645\n",
      "style cost = 88839750.0\n",
      "Iteration 20 :\n",
      "total cost = 369577820.0\n",
      "content cost = 23543.45\n",
      "style cost = 9233560.0\n",
      "Iteration 40 :\n",
      "total cost = 135825820.0\n",
      "content cost = 24721.4\n",
      "style cost = 3389465.2\n",
      "Iteration 60 :\n",
      "total cost = 78894220.0\n",
      "content cost = 25163.18\n",
      "style cost = 1966064.9\n",
      "Iteration 80 :\n",
      "total cost = 57181860.0\n",
      "content cost = 25389.006\n",
      "style cost = 1423199.2\n"
     ]
    }
   ],
   "source": [
    "# reset the Tensorfloat graph and get the variables ready.\n",
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    generated_image = generate_noise_image(content_image)  # add some noise to give some texture.\n",
    "    model = load_vgg_model(\"pretrained-model/imagenet-vgg-verydeep-19.mat\") # load the model. \n",
    "    # Assign the content image to be the input of the VGG model.\n",
    "    sess.run(model['input'].assign(content_image))\n",
    "    out = model['conv4_2']\n",
    "    a_C = sess.run(out)\n",
    "    a_G = out\n",
    "    # Compute the content cost\n",
    "    J_content = compute_content_cost(a_C, a_G)\n",
    "    # Assign the input of the model to be the \"style\" image\n",
    "    sess.run(model['input'].assign(style_image))\n",
    "    # Compute the style cost\n",
    "    J_style = compute_style_cost(sess, model, STYLE_LAYERS)\n",
    "    J = total_cost(J_content, J_style, alpha=10, beta=40)\n",
    "    # define optimizer (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(2.0)\n",
    "    # define train_step (1 line)\n",
    "    train_step = optimizer.minimize(J)\n",
    "    model_nn(sess, model, train_step, J, J_content, J_style, generated_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output/generated_image.jpg\" width=400 alt=\"DEVI picture\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check in the [outputs folder](./output/) of this lab for the images that were created.  A new image is written every 20 iterations.  Contrast and find the ones you like the best. You may also decide to upload new pictures to the images directory and modify the code to generate your own art.  You can change the style and the content!  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
